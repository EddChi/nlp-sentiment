# NLP Sentiment Analysis with IMDb Reviews

## ðŸ“‘ Overview
This project explores sentiment analysis using IMDb reviews dataset.
We compare:
- **Logistic Regression + TF-IDF** (baseline)
- **DistilBERT fine-tuning** (transfer learning)

## ðŸ“‚ Project Structure
nlp-sentiment-analysis/
â”‚
â”œâ”€â”€ data/                 # Raw and processed data (ignored in GitHub)
â”œâ”€â”€ notebooks/            # Jupyter notebooks
â”‚   â”œâ”€â”€ 01_data_eda.ipynb             # Exploratory data analysis
â”‚   â”œâ”€â”€ 02_baseline_model.ipynb       # Logistic Regression baseline
â”‚   â”œâ”€â”€ 03_transformer_model.ipynb    # DistilBERT fine-tuning
â”‚   â””â”€â”€ 04_evaluation_and_reporting.ipynb # Comparison & reporting
â”‚
â”œâ”€â”€ reports/
|   â”œâ”€â”€ final_report.pdf  # Final report
â”‚   â””â”€â”€ figures/          # Plots and visualisations
|
â”‚
â”œâ”€â”€ src/                  # Source code (future: inference scripts, utils)
â”œâ”€â”€ requirements.txt      # Project dependencies
â”œâ”€â”€ README.md             # Project overview
â””â”€â”€ .gitignore            # Ignore large/unnecessary files

## ðŸ“Š Notebooks

**01_data_eda.ipynb**
- Load IMDB dataset
- Explore class balance, review lengths, sample text

**02_baseline_model.ipynb**
- Feature extraction with TFâ€“IDF
- Logistic Regression classifier
- Accuracy ~89%

**03_transformer_model.ipynb**
- Tokenisation with DistilBERT tokenizer
- Fine-tuned DistilBERT for sentiment classification
- Accuracy ~87% (subset, 2 epochs)

**04_evaluation_and_reporting.ipynb**
- Aggregate results
- Compare Logistic Regression vs DistilBERT (Accuracy, Precision, Recall, F1)
- Visualisation + analysis
- Discussion on trade-offs and future improvements

## ðŸ“ˆ Results  

| Model                   | Accuracy | Precision | Recall | F1   |
|-------------------------|----------|-----------|--------|------|
| Logistic Regression     | 0.892    | 0.89      | 0.89   | 0.89 |
| DistilBERT (subset, 2e) | 0.870    | ~0.86     | ~0.87  | ~0.87 |

![Model Comparison](reports/figures/model_comparison.png)

## ðŸš€ Future Work
- Train DistilBERT on full dataset
- Try BERT-base / RoBERTa
- Advanced evaluation (confusion matrices, ROC-AUC)
- Inference script for new reviews