# NLP Sentiment Analysis with IMDb Reviews

## ğŸ“‘ Overview
This project explores sentiment analysis using IMDb reviews dataset.
We compare:
- **Logistic Regression + TF-IDF** (baseline)
- **DistilBERT fine-tuning** (transfer learning)

## ğŸ“‚ Project Structure
```
nlp-sentiment-analysis/
â”œâ”€â”€ .venv/
â”œâ”€â”€ .vscode/
â”‚ â””â”€â”€ settings.json
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ processed/
â”‚ â”‚ â”œâ”€â”€ test.csv
â”‚ â”‚ â”œâ”€â”€ train.csv
â”‚ â”‚ â””â”€â”€ valid.csv
â”‚ â””â”€â”€ raw/
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ results/
â”‚ â”œâ”€â”€ 01_data_eda.ipynb                     # Exploratory data analysis
â”‚ â”œâ”€â”€ 02_baseline_model.ipynb               # Logistic Regression baseline
â”‚ â”œâ”€â”€ 03_transformer_model.ipynb            # DistilBERT fine-tuning
â”‚ â””â”€â”€ 04_evaluation_and_reporting.ipynb     # Comparison & reporting
â”œâ”€â”€ reports/
â”‚ â””â”€â”€ figures/
â”‚ â””â”€â”€ model_comparison.png
â”œâ”€â”€ src/
â”œâ”€â”€ .gitattributes
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

## âš™ï¸ Setup
1. Clone this repository
```
git clone https://github.com/EddChi/nlp-sentiment-analysis.git
cd nlp-sentiment-analysis
```
2. Create and activate a virtual environment
Windows (PowerShell):
```
python -m venv .venv
.venv\Scripts\Activate.ps1
```
Mac/Linux:
```
python3 -m venv .venv
source .venv/bin/activate
```
3. Install dependencies
```pip install -r requirements.txt```
4. Launch Jupyter Notebook
Navigate to the `notebooks/` folder to run each stage of the project.

## ğŸ“Š Notebooks

**01_data_eda.ipynb**
- Load IMDB dataset
- Explore class balance, review lengths, sample text

**02_baseline_model.ipynb**
- Feature extraction with TFâ€“IDF
- Logistic Regression classifier
- Accuracy ~89%

**03_transformer_model.ipynb**
- Tokenisation with DistilBERT tokenizer
- Fine-tuned DistilBERT for sentiment classification
- Accuracy ~87% (subset, 2 epochs)

**04_evaluation_and_reporting.ipynb**
- Aggregate results
- Compare Logistic Regression vs DistilBERT (Accuracy, Precision, Recall, F1)
- Visualisation + analysis
- Discussion on trade-offs and future improvements

## ğŸ“ˆ Results  

| Model                   | Accuracy | Precision | Recall | F1   |
|-------------------------|----------|-----------|--------|------|
| Logistic Regression     | 0.892    | 0.89      | 0.89   | 0.89 |
| DistilBERT (subset, 2e) | 0.870    | ~0.86     | ~0.87  | ~0.87 |

![Model Comparison](reports/figures/model_comparison.png)

## ğŸš€ Future Work
- Train DistilBERT on full dataset
- Try BERT-base / RoBERTa
- Advanced evaluation (confusion matrices, ROC-AUC)
- Inference script for new reviews

## ğŸ“œ License
This project is licensed under the [MIT License](LICENSE).